{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1mJfvXIukq6gt0omZckDBqIFUm_m3X20W","timestamp":1742300966023},{"file_id":"1IHCvryv8PTb5bLHYDnCzKi0_gRk0nC43","timestamp":1742220938763},{"file_id":"1et9g8cCBZTQCBGhK0koe2LIa63UVvfPq","timestamp":1735764201139}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Multi-Armed Bandit Problem\n","O **Problema do Bandido Multibraço (Multi-Armed Bandit)** é um problema fundamental em **Aprendizado por Reforço (Reinforcement Learning)**, frequentemente usado para estudar o equilíbrio entre **exploration** e **exploitation**. Ele envolve um agente que toma decisões (puxar as alavancas de um bandido) para maximizar a recompensa total ao longo do tempo.\n","\n","---\n","<center>\n","<img src='https://drive.google.com/uc?id=177eky4Cxh9qatjxckv2KPB6odrRAR4if' width=600>\n","</center>\n","\n","### Configuração do Problema\n","\n","1. **Cenário**:\n","   - Imagine uma máquina caça-níqueis (um \"bandido\") com $ n $ alavancas.\n","   - Cada alavanca $ i $ fornece uma recompensa retirada de uma distribuição de probabilidade desconhecida com recompensa esperada $ \\mu_i $.\n","\n","2. **Objetivo**:\n","   - Identificar a melhor alavanca (ou um conjunto de boas alavancas) que maximiza a recompensa esperada ao longo de $ T $ passos de tempo.\n","\n","3. **Dilema (Trade-Off)**:\n","   - **Exploration**: Experimentar alavancas para coletar mais informações sobre suas recompensas.\n","   - **Exploitation**: Escolher a alavanca que, com base nas informações anteriores, parece ser a melhor.\n","\n","---\n","\n","### Algoritmos para Resolver o Problema\n","\n","Diversos algoritmos foram desenvolvidos para lidar com o dilema exploração-exploração:\n","\n","#### 1. **Algoritmo ε-Greedy**\n","   - Com probabilidade $ \\epsilon $, explora (escolhe uma alavanca aleatória).\n","   - Com probabilidade $ 1 - \\epsilon $, explora (escolhe a alavanca com a maior recompensa estimada).\n","\n","  Pseudocódigo:\n","  ```python\n","  if random() < epsilon:\n","      action = random_arm()\n","  else:\n","      action = arm_with_highest_estimated_reward()\n","   ```\n","\n","#### 2. **UCB (Upper Confidence Bound)**\n","   - Equilibra exploração e exploração usando um intervalo de confiança para cada alavanca.\n","   - Escolhe a alavanca com o maior limite superior:\n","     $$\n","     a_t = \\arg\\max_i \\left( \\hat{\\mu}_i + \\sqrt{\\frac{2 \\ln t}{n_i}} \\right)\n","     $$\n","     Onde:\n","     - $ \\hat{\\mu}_i $: Recompensa estimada da alavanca $ i $.\n","     - $ n_i $: Número de vezes que a alavanca $ i $ foi escolhida.\n","     - $ t $: Passo de tempo atual.\n","\n","#### 3. **Thompson Sampling**\n","   - Uma abordagem Bayesiana para equilibrar exploração e exploração.\n","   - Modela a recompensa de cada alavanca como uma distribuição de probabilidade e escolhe ações com base em amostras dessas distribuições.\n","\n","#### 4. **Seleção Softmax**\n","   - Usa uma abordagem probabilística para escolher alavancas com base em suas recompensas estimadas.\n","   - A probabilidade de escolher a alavanca $ i $ é proporcional a:\n","$$P(i) = \\frac{e^{\\hat{\\mu}_i / \\tau}}{\\sum_{j}^{e^{\\hat{\\mu}_i / \\tau}}}$$\n","Onde $\\tau$ (temperatura) controla o equilíbrio entre *exploration-exploitation trade-off*.\n","\n","---\n","\n","### Exemplo em Python: Algoritmo ε-Greedy\n","\n","Aqui está uma implementação básica do algoritmo **ε-Greedy**:\n","\n","```python\n","import numpy as np\n","\n","# Configuração\n","num_arms = 5\n","num_steps = 1000\n","true_rewards = np.random.rand(num_arms)  # Recompensas verdadeiras para cada alavanca\n","epsilon = 0.1  # Taxa de exploração\n","\n","# Inicialização\n","estimated_rewards = np.zeros(num_arms)  # Recompensas estimadas\n","counts = np.zeros(num_arms)  # Número de vezes que cada alavanca foi escolhida\n","total_reward = 0\n","\n","# Simulação\n","for t in range(num_steps):\n","    if np.random.rand() < epsilon:\n","        # Explorar: Escolher uma alavanca aleatória\n","        arm = np.random.randint(num_arms)\n","    else:\n","        # Explorar: Escolher a alavanca com a maior recompensa estimada\n","        arm = np.argmax(estimated_rewards)\n","    \n","    # Puxar a alavanca escolhida\n","    reward = np.random.rand() < true_rewards[arm]  # Recompensa binária simulada (0 ou 1)\n","    \n","    # Atualizar estimativas\n","    counts[arm] += 1\n","    estimated_rewards[arm] += (reward - estimated_rewards[arm]) / counts[arm]\n","    \n","    # Atualizar recompensa total\n","    total_reward += reward\n","\n","print(f\"Recompensa Total: {total_reward}\")\n","print(f\"Recompensas Verdadeiras: {true_rewards}\")\n","print(f\"Recompensas Estimadas: {estimated_rewards}\")\n","```\n","\n","---\n","\n","### Métricas-Chave\n","\n","1. **Regret (Arrependimento)**:\n","   - Mede a perda causada por não escolher sempre a melhor alavanca.\n","   - $ R(T) = T \\cdot \\mu^* - \\sum_{t=1}^T \\mu_{a_t} $\n","     - $ \\mu^* $: Recompensa esperada da melhor alavanca.\n","     - $ \\mu_{a_t} $: Recompensa esperada da alavanca escolhida no tempo $ t $.\n","\n","2. **Recompensa Cumulativa**:\n","   - Recompensa total obtida ao longo de $ T $ passos de tempo.\n","\n","---\n","\n","### Aplicações\n","\n","1. **Sistemas de Recomendação**:\n","   - Sugerir itens com base nas preferências do usuário (e.g., filmes, produtos).\n","\n","2. **Ensaios Clínicos**:\n","   - Testar diferentes tratamentos enquanto maximiza os resultados dos pacientes.\n","\n","3. **Publicidade Online**:\n","   - Escolher anúncios que maximizem a taxa de cliques.\n","\n","4. **IA para Jogos**:\n","   - Equilibrar exploração e exploração em tomadas de decisão estratégicas.\n","\n","O **Problema do Bandido Multibraço** é um modelo simples, mas poderoso, que serve como ponto de partida para entender problemas mais complexos no aprendizado por reforço!"],"metadata":{"id":"yOgAxV2WYLJv"}},{"cell_type":"markdown","source":["<img src='https://drive.google.com/uc?id=1d9hu840vJZME9rJhJQJpBC6hFYt7zgtB' width=700>"],"metadata":{"id":"hWtPFyKJrbTb"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Setup\n","num_arms = 5\n","num_steps = 1000000\n","np.random.seed(10)\n","# true_rewards = np.random.rand(num_arms)  # True reward probabilities for each arm\n","true_rewards = [0.2, 0.5, 0.8, 0.7, 0.1]  # Probabilidades reais de recompensa para cada alavanca\n","epsilon = 0.2  # Exploration rate\n","\n","# Initialization\n","estimated_rewards = np.zeros(num_arms)  # Estimated rewards for each arm\n","counts = np.zeros(num_arms)  # Number of times each arm was pulled\n","total_reward = 0\n","rwds = [0]\n","# Simulation\n","for t in range(num_steps):\n","    if np.random.rand() < epsilon:\n","        # Explore: Choose a random arm\n","        arm = np.random.randint(num_arms)\n","    else:\n","        # Exploit: Choose the arm with the highest estimated reward\n","        arm = np.argmax(estimated_rewards)\n","\n","    # Pull the chosen arm\n","    reward = np.random.rand() < true_rewards[arm]  # Simulated binary reward (0 or 1)\n","\n","    # Update estimates\n","    counts[arm] += 1\n","    estimated_rewards[arm] += (reward - estimated_rewards[arm]) / counts[arm]\n","\n","    # Update total reward\n","    total_reward += reward\n","    rwds.append(np.mean(estimated_rewards))\n","\n","# print(f\"Total Reward: {total_reward}\")\n","# print(f\"True Rewards: {true_rewards}\")\n","# print(f\"Estimated Rewards: {estimated_rewards}\")\n","\n","# Resultados\n","print(\"Probabilidades Reais: \", true_rewards)\n","print(\"Recompensas Estimadas: \", estimated_rewards)\n","print(\"Seleções por Alavanca: \", counts)\n","print(\"Recompensa Cumulativa Total: \", total_reward)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"axNZPihqcRtH","executionInfo":{"status":"ok","timestamp":1742302416994,"user_tz":180,"elapsed":20360,"user":{"displayName":"Mauricio Noris Freire","userId":"15384953787911644051"}},"outputId":"66579a6d-cb26-4fcc-ba1a-57c56e3cefc3"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Probabilidades Reais:  [0.2, 0.5, 0.8, 0.7, 0.1]\n","Recompensas Estimadas:  [0.19934358 0.49862488 0.79924302 0.70063057 0.1006782 ]\n","Seleções por Alavanca:  [ 40523.  39633. 839921.  39964.  39959.]\n","Recompensa Cumulativa Total:  731164\n"]}]},{"cell_type":"code","source":["mean_true_rwds = sum(true_rewards)/num_arms\n","print('Média das probabilidades de recompensas reais: %.3f' % mean_true_rwds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Cqy9rHLEoro","executionInfo":{"status":"ok","timestamp":1742302499633,"user_tz":180,"elapsed":28,"user":{"displayName":"Mauricio Noris Freire","userId":"15384953787911644051"}},"outputId":"82cdf9e5-8a5f-4398-c2a2-4e699c713921"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Média das probabilidades de recompensas reais: 0.460\n"]}]},{"cell_type":"code","source":["mean_estimated_rwds = np.mean(estimated_rewards)\n","print('Média das probabilidades de recompensas estimadas: %.3f' % float(mean_estimated_rwds))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4AT_OnMqGIgU","executionInfo":{"status":"ok","timestamp":1742302504556,"user_tz":180,"elapsed":4,"user":{"displayName":"Mauricio Noris Freire","userId":"15384953787911644051"}},"outputId":"d46ee928-e3ca-4fdd-ed8c-a8aafe2be472"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Média das probabilidades de recompensas estimadas: 0.460\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.plot(rwds)\n","plt.title('Average rewards')\n","plt.xlabel('time steps')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"id":"G37q1HIDoBV1","executionInfo":{"status":"ok","timestamp":1742302507379,"user_tz":180,"elapsed":608,"user":{"displayName":"Mauricio Noris Freire","userId":"15384953787911644051"}},"outputId":"bc5e3482-4b40-4657-969c-fd5ec4bc6573"},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## Atualizar a estimativa de recompensa\n","\n","```python\n","# Update estimates\n","counts[arm] += 1\n","estimated_rewards[arm] += (reward - estimated_rewards[arm]) / counts[arm]\n","\n","```\n","Esta parte do código é responsável por **atualizar a estimativa de recompensa média** para a alavanca escolhida com base no novo resultado obtido (recompensa). Vamos detalhar cada linha:\n","\n","---\n","\n","### Linha 1: `counts[arm] += 1`\n","\n","- **O que faz:** Incrementa o contador de quantas vezes a alavanca $ arm $ foi puxada.\n","- **Por que é necessário:**\n","  - Para calcular a média incremental, precisamos saber o número total de vezes que a alavanca foi escolhida.\n","  - Esse valor será usado no cálculo da nova média.\n","\n","Exemplo:\n","- Se a alavanca $ 2 $ foi puxada 3 vezes anteriormente, após esta linha, o contador será atualizado para 4.\n","\n","---\n","\n","### Linha 2: `estimated_rewards[arm] += (reward - estimated_rewards[arm]) / counts[arm]`\n","\n","Essa linha usa a **fórmula de atualização incremental da média** para ajustar a recompensa estimada ($ \\hat{\\mu}_i $) da alavanca $ arm $ com base na nova recompensa $ reward $.\n","\n","#### **Fórmula de Atualização Incremental**\n","A fórmula básica da média é:\n","$$\n","\\hat{\\mu}_i = \\frac{\\text{soma dos valores observados}}{\\text{número de observações}}\n","$$\n","No entanto, recalcular a soma de todos os valores observados a cada atualização é ineficiente. Em vez disso, usamos uma fórmula incremental para atualizar a média sem precisar armazenar todas as recompensas anteriores:\n","\n","$$\n","\\hat{\\mu}_i \\gets \\hat{\\mu}_i + \\frac{\\text{(nova recompensa - média atual)}}{\\text{número de vezes que a alavanca foi puxada}}\n","$$\n","\n","- **Parte 1:** $(\\text{reward} - \\text{estimated_rewards[arm]})$\n","  - Calcula a diferença entre a recompensa recém-obtida ($ reward $) e a recompensa média atual estimada ($ \\text{estimated_rewards[arm]} $).\n","  - Essa diferença indica o quanto o novo valor difere da média atual.\n","\n","- **Parte 2:** $(\\text{reward} - \\text{estimated_rewards[arm]}) / \\text{counts[arm]}$\n","  - Ajusta a diferença pelo número total de vezes que a alavanca foi puxada.\n","  - Isso garante que a média seja alterada de forma gradual e proporcional à quantidade de dados já observados.\n","\n","- **Parte 3:** `estimated_rewards[arm] += ...`\n","  - Atualiza a recompensa média incrementalmente, incorporando a nova observação.\n","\n","#### Exemplo Prático:\n","Imagine que:\n","- A recompensa estimada atual para a alavanca $ 2 $ seja $ \\hat{\\mu}_2 = 0.5 $,\n","- Essa alavanca foi puxada 4 vezes,\n","- A nova recompensa obtida ($ reward $) seja $ 1.0 $.\n","\n","1. **Atualizar o contador**:\n","   $$\n","   \\text{counts[2]} \\gets 5\n","   $$\n","\n","2. **Calcular a diferença entre a nova recompensa e a média atual**:\n","   $$\n","   \\text{(reward - estimated_rewards[2])} = 1.0 - 0.5 = 0.5\n","   $$\n","\n","3. **Atualizar a média**:\n","   $$\n","   \\text{estimated_rewards[2]} \\gets 0.5 + \\frac{0.5}{5} = 0.5 + 0.1 = 0.6\n","   $$\n","\n","Agora, a recompensa média estimada para a alavanca $ 2 $ foi ajustada para $ 0.6 $, levando em consideração a nova observação.\n","\n","---\n","\n","### Por que usar a fórmula incremental?\n","\n","1. **Eficiência Computacional**:\n","   - Não precisamos armazenar todas as recompensas passadas para recalcular a média.\n","   - Apenas o valor atual da média e o número de observações são suficientes.\n","\n","2. **Atualização Dinâmica**:\n","   - Cada nova recompensa tem menos impacto na média à medida que o número de observações aumenta, o que reflete melhor a confiança na estimativa.\n","\n","---\n","\n","### Resumo\n","Essa fórmula de atualização é uma maneira elegante e eficiente de calcular a média incrementalmente, permitindo que o algoritmo ajuste continuamente sua estimativa de recompensa com base em novos dados. É especialmente útil em problemas como o bandido multibraço, onde as recompensas são observadas progressivamente."],"metadata":{"id":"_9YuyHol9vjQ"}},{"cell_type":"markdown","source":["##Passoa a passo"],"metadata":{"id":"FtoLytlDDnn9"}},{"cell_type":"code","source":["num_arms = 5\n","estimated_rewards = np.zeros(num_arms)  # Estimated rewards for each arm\n","counts = np.zeros(num_arms)  # Number of times each arm was pulled\n","total_reward = 0\n","print(estimated_rewards)\n","print(counts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8vwxPDeA5qzj","executionInfo":{"status":"ok","timestamp":1742230814302,"user_tz":180,"elapsed":6,"user":{"displayName":"Prof. Leonimer","userId":"00344305044039680920"}},"outputId":"809a0696-ee86-481d-9a90-65721f03c182"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0.]\n"]}]},{"cell_type":"code","source":["# true_rewards = np.random.rand(num_arms)\n","true_rewards = [0.2, 0.5, 0.8, 0.7, 0.1]  # Probabilidades reais de recompensa para cada alavanca\n","true_rewards"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TfIddsyP6dxB","executionInfo":{"status":"ok","timestamp":1742230816286,"user_tz":180,"elapsed":34,"user":{"displayName":"Prof. Leonimer","userId":"00344305044039680920"}},"outputId":"4e7677b2-badf-4d25-c155-5a16f3d66ff1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.2, 0.5, 0.8, 0.7, 0.1]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["epsilon"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VvnMI2C956ny","executionInfo":{"status":"ok","timestamp":1735752995512,"user_tz":180,"elapsed":248,"user":{"displayName":"Prof. Leonimer","userId":"00344305044039680920"}},"outputId":"b855281b-15b1-406c-a9c3-7ab07cd85689"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.2"]},"metadata":{},"execution_count":146}]},{"cell_type":"markdown","source":["⬇️ Começa o loop:"],"metadata":{"id":"6t8VHpNa6rlZ"}},{"cell_type":"code","source":["c = np.random.rand()\n","c"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GFugniQZ5zFJ","executionInfo":{"status":"ok","timestamp":1735754641573,"user_tz":180,"elapsed":221,"user":{"displayName":"Prof. Leonimer","userId":"00344305044039680920"}},"outputId":"6088e553-4453-4254-c973-627ab48f71a4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.1811683077412788"]},"metadata":{},"execution_count":274}]},{"cell_type":"code","source":["if c < epsilon:\n","    # Explore: Choose a random arm\n","    arm = np.random.randint(num_arms)\n","    print('exploration')\n","else:\n","    # Exploit: Choose the arm with the highest estimated reward\n","    arm = np.argmax(estimated_rewards)\n","    print('exploitation')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lRLWKQ765udx","executionInfo":{"status":"ok","timestamp":1735754655127,"user_tz":180,"elapsed":217,"user":{"displayName":"Prof. Leonimer","userId":"00344305044039680920"}},"outputId":"156318b4-ff9f-4719-ba10-a1ad5d4b4815"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["exploration\n"]}]},{"cell_type":"code","source":["arm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OB6SQYqC24za","executionInfo":{"status":"ok","timestamp":1735754657928,"user_tz":180,"elapsed":234,"user":{"displayName":"Prof. Leonimer","userId":"00344305044039680920"}},"outputId":"51fe68fa-9ced-4edb-d001-b99751988d8f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":280}]},{"cell_type":"code","source":["true_rewards[arm]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OQ9QCApd20Ii","executionInfo":{"status":"ok","timestamp":1735754661061,"user_tz":180,"elapsed":214,"user":{"displayName":"Prof. Leonimer","userId":"00344305044039680920"}},"outputId":"08a4e484-9d60-4480-efd5-7c9460f4548c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.34114790713481635"]},"metadata":{},"execution_count":281}]},{"cell_type":"code","source":["r = np.random.rand()\n","r"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LTRHQnOM3Gb6","executionInfo":{"status":"ok","timestamp":1735754662265,"user_tz":180,"elapsed":241,"user":{"displayName":"Prof. Leonimer","userId":"00344305044039680920"}},"outputId":"c70b43ef-c1d5-48ec-9da9-36bb5763fc2d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.17470270334649896"]},"metadata":{},"execution_count":282}]},{"cell_type":"code","source":["# Pull the chosen arm and receve the reward (or not!)\n","reward = r < true_rewards[arm]\n","# reward is binary: True (=1) or False (=0)\n","reward"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iu2Ix7XL3Nvs","executionInfo":{"status":"ok","timestamp":1735754663997,"user_tz":180,"elapsed":222,"user":{"displayName":"Prof. Leonimer","userId":"00344305044039680920"}},"outputId":"94f7bdd5-96d1-476d-f5d6-a3ad7960865e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":283}]},{"cell_type":"code","source":["counts[arm] += 1\n","counts[arm]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1k_KAHej3prD","executionInfo":{"status":"ok","timestamp":1735754665297,"user_tz":180,"elapsed":252,"user":{"displayName":"Prof. Leonimer","userId":"00344305044039680920"}},"outputId":"c734fe1c-4df8-41b3-8b0d-45fe100c3541"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5.0"]},"metadata":{},"execution_count":284}]},{"cell_type":"code","source":["counts"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QIsl78Pz8q1r","executionInfo":{"status":"ok","timestamp":1735754667286,"user_tz":180,"elapsed":219,"user":{"displayName":"Prof. Leonimer","userId":"00344305044039680920"}},"outputId":"d519cbe3-655a-430c-d124-285eeb1a6220"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([2., 0., 4., 5., 0.])"]},"metadata":{},"execution_count":285}]},{"cell_type":"code","source":["estimated_rewards"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YET_mjvK8-3Q","executionInfo":{"status":"ok","timestamp":1735754668242,"user_tz":180,"elapsed":3,"user":{"displayName":"Prof. Leonimer","userId":"00344305044039680920"}},"outputId":"4f4e0109-dec1-4400-a6b3-9a870ebc9720"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0. , 0. , 1. , 0.5, 0. ])"]},"metadata":{},"execution_count":286}]},{"cell_type":"code","source":["e = estimated_rewards[arm]\n","e"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-MH58jkw4HlE","executionInfo":{"status":"ok","timestamp":1735754669488,"user_tz":180,"elapsed":246,"user":{"displayName":"Prof. Leonimer","userId":"00344305044039680920"}},"outputId":"69742e5f-1b57-4ee1-ab3b-b162dc505240"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5"]},"metadata":{},"execution_count":287}]},{"cell_type":"code","source":["# Calcula a diferença entre a recompensa recém-obtida (reward) e a recompensa média atual estimada\n","a = reward - e\n","a"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lvniCVPT30ia","executionInfo":{"status":"ok","timestamp":1735754671710,"user_tz":180,"elapsed":244,"user":{"displayName":"Prof. Leonimer","userId":"00344305044039680920"}},"outputId":"f70a1a9f-b0a1-4e3d-caf3-0b30612265e7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5"]},"metadata":{},"execution_count":288}]},{"cell_type":"code","source":["# Ajusta a diferença pelo número total de vezes que a alavanca foi puxada\n","b = a / counts[arm]\n","b"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A6riAc7c4456","executionInfo":{"status":"ok","timestamp":1735754674184,"user_tz":180,"elapsed":214,"user":{"displayName":"Prof. Leonimer","userId":"00344305044039680920"}},"outputId":"03ce5706-5957-4e42-8d39-3ac4dd3e83ad"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.1"]},"metadata":{},"execution_count":289}]},{"cell_type":"code","source":["# Atualiza a recompensa média incrementalmente\n","estimated_rewards[arm] = estimated_rewards[arm] + b\n","estimated_rewards[arm]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qFK-C28J5HFC","executionInfo":{"status":"ok","timestamp":1735754677160,"user_tz":180,"elapsed":236,"user":{"displayName":"Prof. Leonimer","userId":"00344305044039680920"}},"outputId":"7bb5c733-cfd9-471f-adac-abeebcb1af9b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6"]},"metadata":{},"execution_count":290}]},{"cell_type":"code","source":["total_reward += reward\n","total_reward"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aZy1B7AV5Tb7","executionInfo":{"status":"ok","timestamp":1735754680900,"user_tz":180,"elapsed":268,"user":{"displayName":"Prof. Leonimer","userId":"00344305044039680920"}},"outputId":"537f994e-37a0-4827-edda-0dbc5a4a5cb8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9"]},"metadata":{},"execution_count":291}]},{"cell_type":"markdown","source":["⬆️ Retorna ao loop"],"metadata":{"id":"Ikubt1Fc7h7R"}},{"cell_type":"markdown","source":["### Exemplo de Recompensa Cumulativa no Problema do Bandido Multibraço\n","\n","A **recompensa cumulativa** é a soma das recompensas obtidas ao longo de vários passos de tempo. Vamos construir um exemplo prático baseado no algoritmo **ε-Greedy** para calcular a recompensa cumulativa ao final de uma simulação.\n","\n","---\n","\n","### Código: Calculando Recompensa Cumulativa"],"metadata":{"id":"sopzKqYmBEEA"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Configuração\n","num_arms = 3  # Número de alavancas\n","num_steps = 1000  # Número de passos\n","true_rewards = [0.2, 0.5, 0.8]  # Probabilidades reais de recompensa para cada alavanca\n","epsilon = 0.1  # Taxa de exploração\n","\n","# Inicialização\n","estimated_rewards = np.zeros(num_arms)  # Recompensas estimadas\n","counts = np.zeros(num_arms)  # Contador de seleções por alavanca\n","total_reward = 0  # Recompensa cumulativa inicial\n","\n","# Simulação\n","for step in range(num_steps):\n","    # Escolher alavanca: Explorar ou Explorar\n","    if np.random.rand() < epsilon:\n","        arm = np.random.randint(num_arms)  # Escolher alavanca aleatória (explorar)\n","    else:\n","        arm = np.argmax(estimated_rewards)  # Escolher alavanca com maior recompensa estimada (explorar)\n","\n","    # Puxar a alavanca escolhida e obter recompensa\n","    reward = np.random.rand() < true_rewards[arm]  # Simula recompensa (0 ou 1)\n","\n","    # Atualizar estimativas\n","    counts[arm] += 1\n","    estimated_rewards[arm] += (reward - estimated_rewards[arm]) / counts[arm]\n","\n","    # Atualizar recompensa cumulativa\n","    total_reward += reward\n","\n","# Resultados\n","print(\"Probabilidades Reais: \", true_rewards)\n","print(\"Recompensas Estimadas: \", estimated_rewards)\n","print(\"Seleções por Alavanca: \", counts)\n","print(\"Recompensa Cumulativa Total: \", total_reward)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0wEn8deOgXf7","executionInfo":{"status":"ok","timestamp":1742230173573,"user_tz":180,"elapsed":6,"user":{"displayName":"Prof. Leonimer","userId":"00344305044039680920"}},"outputId":"7e2a5c60-bc8e-4f45-9d66-013ed94a7a52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Probabilidades Reais:  [0.2, 0.5, 0.8]\n","Recompensas Estimadas:  [0.22222222 0.50953678 0.77889447]\n","Seleções por Alavanca:  [ 36. 367. 597.]\n","Recompensa Cumulativa Total:  660\n"]}]},{"cell_type":"markdown","source":["### Explicação dos Resultados\n","\n","1. **Recompensas Verdadeiras**:\n","   - A probabilidade real de cada alavanca fornecer uma recompensa (exemplo: 20%, 50%, e 80%).\n","\n","2. **Recompensas Estimadas**:\n","   - As estimativas calculadas pelo agente com base nas interações.\n","\n","3. **Seleções por Alavanca**:\n","   - Quantas vezes cada alavanca foi puxada.\n","\n","4. **Recompensa Cumulativa Total**:\n","   - A soma de todas as recompensas obtidas durante os $ num\\_steps $.\n","\n","---\n","\n","### Interpretação da Recompensa Cumulativa\n","\n","- Quanto mais o algoritmo consegue explorar as alavancas certas (com maior probabilidade de recompensa), maior será a **recompensa cumulativa**.\n","- No exemplo, a alavanca com 80% de probabilidade de recompensa foi puxada com mais frequência, resultando em uma alta recompensa total.\n","\n","Este exemplo ilustra como o conceito de **recompensa cumulativa** mede o sucesso do agente ao equilibrar exploração e exploração no problema do bandido multibraço!"],"metadata":{"id":"ZLNpywFUBTnm"}},{"cell_type":"markdown","source":["##Referências\n","[1] Dong H. **Deep Reinforcement Learning. Fundamentals, Research and Applications**. Springer. 2020.\n","\n","[2] Laura Graesser, Wah Loon Keng. **Foundations of Deep Reinforcement Learning - Theory and Practice in Python**. Pearson Addison-Wesley. 2023.\n","\n","[3] https://aws.amazon.com/pt/what-is/reinforcement-learning/\n","\n","[4] https://www.deeplearningbook.com.br/o-que-e-aprendizagem-por-reforco/\n","\n","[5] https://www.geeksforgeeks.org/what-is-reinforcement-learning/\n","\n","[6] https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n","\n","[7] https://www.datacamp.com/pt/tutorial/reinforcement-learning-python-introduction\n","\n","[8] https://towardsdatascience.com/reinforcement-learning-rl-101-with-python-e1aa0d37d43b\n","\n","[9] https://machinelearningmastery.com/principles-of-reinforcement-learning-an-introduction-with-python/\n","\n","[10] https://medium.com/turing-talks/aprendizado-por-refor%C3%A7o-1-introdu%C3%A7%C3%A3o-7382ebb641ab\n","\n","[11] https://www.datacamp.com/tutorial/reinforcement-learning-python-introduction\n","\n","[12] https://gymnasium.farama.org/introduction/basic_usage/\n","\n","[13] Sudharsan Ravichandiran. **Deep Reinforcement Learning with Python**. Second Edition. Packt Publishing. 2020.\n","\n","[14] Morales, M. **Grokking Deep Reinforcement Learning**. Version 11. Manning Publications. 2020.\n","\n","[15] https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/\n","\n","[16] https://github.com/sudharsan13296/Deep-Reinforcement-Learning-With-Python/tree/master"],"metadata":{"id":"1mPVxR3d8K68"}}]}